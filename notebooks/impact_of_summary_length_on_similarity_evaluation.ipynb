{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0f9fcb-76e1-4a2f-a560-54d6e625eb35",
   "metadata": {},
   "source": [
    "# Impact of Summary Length on Model Comparisons\n",
    "\n",
    "The length of the summary (e.g., 50 vs. 100 vs. 200 words) significantly affects the evaluation metrics used for model comparison.  \n",
    "Below, we analyze the effects for **Cosine Similarity**, **BERT embeddings**, and **Word2Vec** models.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Cosine Similarity (TF-IDF / Bag-of-Words)\n",
    "- **How it works:** Measures similarity based on word frequency without capturing context.  \n",
    "- **Effect of length:**\n",
    "  - Short (<50): More precise but lacks context.  \n",
    "  - Moderate (50–100): Best balance of precision & context.  \n",
    "  - Long (100–200): May introduce noise and unrelated details.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. BERT Embeddings (Sentence Transformers)\n",
    "- **How it works:** Converts sentences into dense embeddings, capturing meaning rather than just word overlap.  \n",
    "- **Effect of length:**\n",
    "  - Short (<50): Lacks context, similarity less reliable.  \n",
    "  - Moderate (50–100): Best performance, balances meaning and detail.  \n",
    "  - Long (100–200): Risk of losing focus due to irrelevant information.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Word2Vec (Word-Level Embeddings)\n",
    "- **How it works:** Captures word meanings but ignores word order and sentence structure.  \n",
    "- **Effect of length:**\n",
    "  - Short (<50): Similarity scores less stable due to fewer embeddings.  \n",
    "  - Moderate (50–100): Best performance for word meaning-based comparisons.  \n",
    "  - Long (100–200): More noise, redundant words affect results.  \n",
    "\n",
    "---\n",
    "\n",
    "##  Summary Table\n",
    "\n",
    "| **Model**         | **Short (<50 words)**       | **Moderate (50–100 words)** | **Long (100–200 words)**       |\n",
    "|--------------------|-----------------------------|------------------------------|--------------------------------|\n",
    "| **Cosine Similarity** | Precise but lacks context |  Best balance of precision & context |  Noise from extra words       |\n",
    "| **BERT**             |  Lacks full context        |  Best performance, balances detail   |  Loses focus, extra info adds noise |\n",
    "| **Word2Vec**         |  Less stable similarity    |  Best word-based comparison         |  Redundant words introduce noise |\n",
    "\n",
    "---\n",
    "\n",
    "##  Final Verdict\n",
    "The **best length range is 50–100 words**:\n",
    "- Provides enough context for **BERT**.  \n",
    "- Keeps precision intact for **Cosine Similarity**.  \n",
    "- Balances representation in **Word2Vec**.  \n",
    "\n",
    "For your project, **50–100 words** will yield the most reliable and comparable results across models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
